import os
from pathlib import Path

# API æä¾›å•†é…ç½®
API_CONFIG = {
    "glm": {
        "api_key_env_var": "GLM_API_Key",
        "api_base": "https://open.bigmodel.cn/api/paas/v4/",
        "llm_model_name": "glm-4-flash",
        "llm_provider_type": "zhipuai",
        "temperature": 0.1
    },
    "ollama": { # æ–°å¢ Ollama é…ç½®
        "api_base": "http://localhost:11434", # Ollama é»˜è®¤ API åœ°å€
        "llm_model_name": "qwen3:4b",           # æ¨¡å‹åˆ—è¡¨åœ¨ http://localhost:11434/api/tags
        "llm_provider_type": "ollama",
        "temperature": 0.7                    # Ollama æ¨¡å‹çš„æ¸©åº¦å‚æ•°
    }
    # æœªæ¥å¯ä»¥æ·»åŠ æ›´å¤šæä¾›å•†çš„é…ç½®
}

# é¡¹ç›®è·¯å¾„é…ç½®
try:
    PROJECT_ROOT = Path(__file__).resolve().parent.parent
except NameError:  # å¤„ç† __file__ ä¸å­˜åœ¨çš„æƒ…å†µ
    PROJECT_ROOT = Path.cwd()

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜
CHROMA_DB_PATH = PROJECT_ROOT / "chroma_db_store"
TEMP_UPLOADS_DIR = PROJECT_ROOT / "temp_uploads"

# æ¨¡å‹é…ç½®
EMBEDDING_MODEL = {
    "local_path": "D:\\0-source\\models\\paraphrase-multilingual-MiniLM-L12-v2",
    "model_name": "paraphrase-multilingual-MiniLM-L12-v2"
}

# æ–‡æ¡£å¤„ç†é…ç½®
DOCUMENT_PROCESSING = {
    "chunk_size": 1024,
    "chunk_overlap": 20
}

# æ”¯æŒçš„æ–‡ä»¶ç±»å‹
SUPPORTED_FILE_TYPES = ["pdf", "txt"]

# UI é…ç½®
UI_CONFIG = {
    "page_title": "PDFæ™ºèƒ½é—®ç­”åŠ©æ‰‹",
    "page_icon": "ğŸ“š",
    "layout": "wide"
}